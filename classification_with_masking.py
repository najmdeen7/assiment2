from detectron2.engine import DefaultTrainer
from detectron2.config import get_cfg
from detectron2 import model_zoo
from detectron2.data import DatasetCatalog, MetadataCatalog
from detectron2.structures import BoxMode
import os
import json
import cv2
import numpy as np
import pycocotools.mask as mask_util
from PIL import Image
from tqdm import tqdm

# ========== ğŸ› ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ==========
TRAIN_JSON = r"D:\\python\\train_fixed.json"
VAL_JSON = r"D:\\python\\val_fixed.json"
SELECTED_IMAGES_DIR = r"D:\\python\\LV-MHP-v2\\selected_images"

# ========== ğŸ—‚ï¸ ÙØ¦Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ==========
CATEGORY_MAPPING = {
    4: 0,  # person
    1: 1,  # man
    2: 2,  # woman
    3: 3   # child
}
CLASS_NAMES = ["person", "man", "woman", "child"]

# ========== ğŸ” ÙØ­Øµ Ø§Ù„ØµÙˆØ± Ø§Ù„ØªØ§Ù„ÙØ© ==========
def check_corrupted_images(json_file):
    corrupted = []
    print(f"\nğŸ” ÙØ­Øµ Ø§Ù„ØµÙˆØ± ÙÙŠ {json_file}...")

    with open(json_file, "r") as f:
        data = json.load(f)

    for img_info in tqdm(data['images']):
        img_path = os.path.join(SELECTED_IMAGES_DIR, img_info['file_name'])
        if not os.path.exists(img_path):
            corrupted.append({
                'image_id': img_info['id'],
                'path': img_path,
                'error': "File not found"
            })
            continue
        try:
            with Image.open(img_path) as img:
                img.verify()
        except Exception as e:
            corrupted.append({
                'image_id': img_info['id'],
                'path': img_path,
                'error': str(e)
            })

    return corrupted

# ========== ğŸ“¦ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ==========
def get_dicts(json_file):
    with open(json_file, "r") as file:
        coco = json.load(file)
    print(f"\nğŸ“‚ ØªØ­Ù…ÙŠÙ„ {len(coco['images'])} ØµÙˆØ±Ø© Ù…Ù† {json_file}...")

    # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ© Ø­Ø³Ø¨ Ù…Ø¹Ø±Ù Ø§Ù„ØµÙˆØ±Ø©
    anns_dict = {ann['image_id']: [] for ann in coco['annotations']}
    for ann in coco['annotations']:
        anns_dict[ann['image_id']].append(ann)

    dataset_dicts = []
    for img_info in coco['images']:
        record = {}
        image_path = os.path.join(SELECTED_IMAGES_DIR, img_info['file_name'])

        if not os.path.exists(image_path):
            print(f"âš ï¸ Ø§Ù„ØµÙˆØ±Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: {image_path}")
            continue

        try:
            img = cv2.imread(image_path)
            if img is None:
                raise ValueError("ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©: {image_path} - {str(e)}")
            continue

        height, width = img.shape[:2]
        record = {
            "file_name": image_path,
            "image_id": img_info['id'],
            "height": height,
            "width": width,
            "annotations": []
        }

        for ann in anns_dict.get(img_info['id'], []):
            try:
                mask_path = ann.get('mask_path')
                if not mask_path or not os.path.exists(mask_path):
                    print(f"âš ï¸ Ø§Ù„Ù‚Ù†Ø§Ø¹ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {mask_path}")
                    continue

                category_id = ann['category_id']
                if category_id not in CATEGORY_MAPPING:
                    print(f"âš ï¸ ÙØ¦Ø© ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©: {category_id}")
                    continue
                mapped_cat_id = CATEGORY_MAPPING[category_id]

                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
                if mask is None:
                    print(f"âš ï¸ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù‚Ù†Ø§Ø¹: {mask_path}")
                    continue

                # âœ… Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù‚Ù†Ø§Ø¹ Ø¨Ù†ÙØ³ Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ØµÙˆØ±Ø©
                mask = cv2.resize(mask, (width, height), interpolation=cv2.INTER_NEAREST)

                # ğŸ”¹ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù‚Ù†Ø§Ø¹ Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠ
                binary_mask = np.zeros_like(mask, dtype=np.uint8)
                if category_id == 2:  # Ø§Ù„Ù…Ø±Ø£Ø©
                    binary_mask[(mask != 3) & (mask != 7) & (mask != 8)] = 1
                else:
                    binary_mask[mask > 0] = 1

                if np.sum(binary_mask) < 50:
                    print(f"âš ï¸ Ù‚Ù†Ø§Ø¹ ØµØºÙŠØ± Ø¬Ø¯Ù‹Ø§: {mask_path} ({np.sum(binary_mask)} Ø¨ÙŠÙƒØ³Ù„)")
                    continue

                # âœ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚Ù†Ø§Ø¹ Ø¥Ù„Ù‰ RLE
                rle = mask_util.encode(np.asfortranarray(binary_mask))
                rle["counts"] = rle["counts"].decode("utf-8")

                record["annotations"].append({
                    "bbox": ann['bbox'],
                    "bbox_mode": BoxMode.XYWH_ABS,
                    "category_id": mapped_cat_id,
                    "segmentation": rle,
                    "iscrowd": 0
                })

            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ {ann['id']}: {str(e)}")
                continue

        if len(record["annotations"]) > 0:
            dataset_dicts.append(record)

    print(f"âœ… ØªÙ… ØªØ¬Ù‡ÙŠØ² {len(dataset_dicts)} ØªØ³Ø¬ÙŠÙ„Ø© ØµØ§Ù„Ø­Ø© Ù…Ù† {json_file}")
    return dataset_dicts

# ========== ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ==========
if __name__ == "__main__":
    # ÙØ­Øµ Ø§Ù„ØµÙˆØ± Ø§Ù„ØªØ§Ù„ÙØ©
    for json_file in [TRAIN_JSON, VAL_JSON]:
        corrupted = check_corrupted_images(json_file)
        if corrupted:
            print(f"\nâŒ ÙŠÙˆØ¬Ø¯ {len(corrupted)} ØµÙˆØ± ØªØ§Ù„ÙØ© ÙÙŠ {json_file}:")
            for c in corrupted:
                print(f"- {c['path']} (Ø§Ù„Ø®Ø·Ø£: {c['error']})")
            exit(1)

    # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª ÙÙŠ Detectron2
    DatasetCatalog.clear()
    DatasetCatalog.register("train_dataset", lambda: get_dicts(TRAIN_JSON))
    MetadataCatalog.get("train_dataset").set(thing_classes=CLASS_NAMES)

    DatasetCatalog.register("val_dataset", lambda: get_dicts(VAL_JSON))
    MetadataCatalog.get("val_dataset").set(thing_classes=CLASS_NAMES)

    # Ø¶Ø¨Ø· Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    cfg = get_cfg()
    cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))

    cfg.DATASETS.TRAIN = ("train_dataset",)
    cfg.DATASETS.TEST = ("val_dataset",)
    cfg.DATALOADER.NUM_WORKERS = 2
    cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = True

    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4
    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64
    cfg.INPUT.MASK_FORMAT = "bitmask"

    cfg.SOLVER.IMS_PER_BATCH = 2
    cfg.SOLVER.BASE_LR = 0.00025
    cfg.SOLVER.MAX_ITER = 12500
    cfg.SOLVER.STEPS = (500, 750)
    cfg.SOLVER.GAMMA = 0.1
    cfg.TEST.EVAL_PERIOD = 200

    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)

    try:
        print("\nğŸš€ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¯Ø±ÙŠØ¨...")
        trainer = DefaultTrainer(cfg)
        trainer.resume_or_load(resume=False)
        trainer.train()
        print("\nğŸ‰ ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ù†Ø¬Ø§Ø­!")
    except Exception as e:
        print(f"\nâŒ ÙØ´Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {str(e)}")
