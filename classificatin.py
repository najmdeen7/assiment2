import os
import json
import cv2
import random
import torch
from detectron2.engine import DefaultTrainer, DefaultPredictor
from detectron2.config import get_cfg
from detectron2 import model_zoo
from detectron2.data import MetadataCatalog, DatasetCatalog, build_detection_test_loader
from detectron2.structures import BoxMode
from detectron2.utils.visualizer import Visualizer
from detectron2.evaluation import COCOEvaluator, inference_on_dataset

# ğŸŸ¢ **ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª**
json_file = r"D:\python\instances_default.json"  # Ù…Ù„Ù JSON Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† CVAT
image_dir = r"D:\python\LV-MHP-v2\selected_images"  # Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ØµÙØ§Ø©
output_dir = r"D:\python\output"  # Ù…Ø¬Ù„Ø¯ Ù„Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
os.makedirs(output_dir, exist_ok=True)

# ğŸŸ¢ **ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† JSON**
with open(json_file, "r") as f:
    dataset = json.load(f)

# ğŸŸ¢ **ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø© Ù…Ø¹ Ø¥Ø¶Ø§ÙØ© Ø¹Ù†ØµØ± ÙØ§Ø±Øº ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©** âœ…
thing_classes = ["", "man", "woman", "child" ]  # âœ… Ø¥Ø¶Ø§ÙØ© Ø¹Ù†ØµØ± ÙØ§Ø±Øº Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ ØªÙ†Ø§Ø³Ù‚ Ø§Ù„ÙÙ‡Ø±Ø³
MetadataCatalog.get("LVMHPV2_train").set(thing_classes=thing_classes)
MetadataCatalog.get("LVMHPV2_val").set(thing_classes=thing_classes)

# ğŸŸ¢ **ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØµÙˆØ± Ø¨ÙŠÙ† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ…**
all_images = dataset["images"]
random.shuffle(all_images)
train_images = all_images[:500]  # 500 ØµÙˆØ±Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨
val_images = all_images[500:700]  # 200 ØµÙˆØ±Ø© Ù„Ù„ØªÙ‚ÙŠÙŠÙ…

# ğŸŸ¢ **Ø¯Ø§Ù„Ø© Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Detectron2**
def get_LVMHPV2_dicts(subset):
    dataset_dicts = []
    for img in subset:
        record = {
            "file_name": os.path.join(image_dir, img["file_name"]),
            "image_id": img["id"],
            "height": img["height"],
            "width": img["width"],
            "annotations": []
        }

        # ğŸŸ¢ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ© Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø©
        annotations = [ann for ann in dataset["annotations"] if ann["image_id"] == img["id"]]
        for ann in annotations:
            category_id = ann["category_id"]  # âœ… Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ÙÙ‡Ø±Ø³ ÙƒÙ…Ø§ Ù‡Ùˆ
            if 1 <= category_id <= 4:  # âœ… ÙÙ‚Ø· Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡Ø§ (man, woman, child)
                record["annotations"].append({
                    "bbox": ann["bbox"],
                    "bbox_mode": BoxMode.XYWH_ABS,
                    "category_id": category_id  # âœ… Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³ Ù„Ø£Ù†Ù‡ Ù…ØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ thing_classes
                })

        dataset_dicts.append(record)
    return dataset_dicts

# ğŸŸ¢ **ØªØ³Ø¬ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ…**
DatasetCatalog.register("LVMHPV2_train", lambda: get_LVMHPV2_dicts(train_images))
DatasetCatalog.register("LVMHPV2_val", lambda: get_LVMHPV2_dicts(val_images))

MetadataCatalog.get("LVMHPV2_train").set(thing_classes=thing_classes)
MetadataCatalog.get("LVMHPV2_val").set(thing_classes=thing_classes)

# ğŸŸ¢ **Ø¹Ø±Ø¶ 3 Ø¹ÙŠÙ†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**
def visualize_samples():
    sample_images = random.sample(train_images, 3)
    for idx, img_data in enumerate(sample_images):
        img_path = os.path.join(image_dir, img_data["file_name"])
        img = cv2.imread(img_path)

        annotations = [ann for ann in dataset["annotations"] if ann["image_id"] == img_data["id"]]

        instances = []
        for ann in annotations:
            category_id = ann["category_id"]
            instances.append({"bbox": ann["bbox"], "bbox_mode": BoxMode.XYWH_ABS, "category_id": category_id})

        visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get("LVMHPV2_train"), scale=0.5)
        out = visualizer.draw_dataset_dict({"annotations": instances})

        output_path = os.path.join(output_dir, f"sample_{idx}.jpg")
        cv2.imwrite(output_path, out.get_image()[:, :, ::-1])
        print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¹ÙŠÙ†Ø© ÙÙŠ: {output_path}")

# ğŸŸ¢ **Ø¹Ø±Ø¶ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨**
visualize_samples()

if __name__ == '__main__':
    # ğŸŸ¢ **Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬**
    cfg = get_cfg()
    cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml"))
    cfg.DATASETS.TRAIN = ("LVMHPV2_train",)
    cfg.DATASETS.TEST = ("LVMHPV2_val",)
    cfg.DATALOADER.NUM_WORKERS = 2
    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml")  # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙˆØ²Ø§Ù† Ù…Ø³Ø¨Ù‚Ø©
    cfg.SOLVER.IMS_PER_BATCH = 2
    cfg.SOLVER.BASE_LR = 0.00025
    cfg.SOLVER.MAX_ITER = 20000  # Ø¹Ø¯Ø¯ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(thing_classes)  # âœ… Ø¶Ø¨Ø· Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª

    # ğŸŸ¢ **Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨**
    trainer = DefaultTrainer(cfg)
    trainer.resume_or_load(resume=False)
    trainer.train()

    # ğŸŸ¢ **Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨**
    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # Ø¹ØªØ¨Ø© Ø§Ù„Ø«Ù‚Ø©
    predictor = DefaultPredictor(cfg)
    val_loader = build_detection_test_loader(cfg, "LVMHPV2_val")

    # ğŸŸ¢ **Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù€ 200 ØµÙˆØ±Ø© Ù…Ù† `selected_images` ÙÙ‚Ø·**
    evaluator = COCOEvaluator("LVMHPV2_val", cfg, False, output_dir=output_dir)
    print(inference_on_dataset(predictor.model, val_loader, evaluator))

    print("âœ… ğŸ‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù†ØªÙ‡Ù‰ Ø¨Ù†Ø¬Ø§Ø­! ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ:", output_dir)
    results_file = os.path.join(output_dir, "coco_instances_results.json")

    # ğŸŸ¢ ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    if os.path.exists(results_file):
        with open(results_file, "r") as f:
            predictions = json.load(f)

        print(f"âœ… Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©: {len(predictions)}")
        print("ğŸ” Ø£ÙˆÙ„ 5 Ù†ØªØ§Ø¦Ø¬ Ù…Ù† Ø§Ù„ØªÙ‚ÙŠÙŠÙ…:")
        for pred in predictions[:5]:
            print(pred)
    else:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª! ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­.")

