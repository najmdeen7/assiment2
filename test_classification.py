import os
import torch
import json
import numpy as np
from detectron2.config import get_cfg
from detectron2.engine import DefaultTrainer, DefaultPredictor
from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader
from detectron2 import model_zoo
SELECTED_IMAGES_DIR = r"D:\\python\\LV-MHP-v2\\selected_images"
def get_dicts(json_file):
    import cv2
    import pycocotools.mask as mask_util
    from detectron2.structures import BoxMode

    with open(json_file, "r") as file:
        coco = json.load(file)
    print(f"\nğŸ“‚ ØªØ­Ù…ÙŠÙ„ {len(coco['images'])} ØµÙˆØ±Ø© Ù…Ù† {json_file}...")

    CATEGORY_MAPPING = {
        4: 0,  # person
        1: 1,  # man
        2: 2,  # woman
        3: 3   # child
    }

    dataset_dicts = []
    for img_info in coco['images']:
        record = {}
        image_path = os.path.join(SELECTED_IMAGES_DIR, img_info['file_name'])

        if not os.path.exists(image_path):
            print(f"âš ï¸ Ø§Ù„ØµÙˆØ±Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: {image_path}")
            continue

        img = cv2.imread(image_path)
        if img is None:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©: {image_path}")
            continue

        height, width = img.shape[:2]
        record["file_name"] = image_path
        record["image_id"] = img_info['id']
        record["height"] = height
        record["width"] = width
        record["annotations"] = []

        for ann in coco['annotations']:
            if ann['image_id'] != img_info['id']:
                continue

            mask_path = ann.get('mask_path')
            if not mask_path or not os.path.exists(mask_path):
                print(f"âš ï¸ Ø§Ù„Ù‚Ù†Ø§Ø¹ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {mask_path}")
                continue

            category_id = ann['category_id']
            if category_id not in CATEGORY_MAPPING:
                print(f"âš ï¸ ÙØ¦Ø© ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©: {category_id}")
                continue
            mapped_cat_id = CATEGORY_MAPPING[category_id]

            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
            if mask is None:
                print(f"âš ï¸ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù‚Ù†Ø§Ø¹: {mask_path}")
                continue

            binary_mask = np.where(mask > 0, 1, 0).astype(np.uint8)

            rle = mask_util.encode(np.asfortranarray(binary_mask))
            rle["counts"] = rle["counts"].decode("utf-8")

            record["annotations"].append({
                "bbox": ann['bbox'],
                "bbox_mode": BoxMode.XYWH_ABS,
                "category_id": mapped_cat_id,
                "segmentation": rle,
                "iscrowd": 0
            })

        if len(record["annotations"]) > 0:
            dataset_dicts.append(record)

    print(f"âœ… ØªÙ… ØªØ¬Ù‡ÙŠØ² {len(dataset_dicts)} ØªØ³Ø¬ÙŠÙ„Ø© ØµØ§Ù„Ø­Ø© Ù…Ù† {json_file}")
    return dataset_dicts
if __name__ == '__main__':
    # ğŸ”¹ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
    MODEL_DIR = r"D:\python\output"  # Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨
    MODEL_WEIGHTS = os.path.join(MODEL_DIR, "â€â€model_final -10000 .pth")  # Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙˆÙ„ Ø¨Ø¯ÙˆÙ† Masking
    VAL_JSON = r"D:\\python\\val_fixed.json"

    # ğŸ”¹ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙˆÙ„ (Classification Ø¨Ø¯ÙˆÙ† Masking)
    cfg = get_cfg()
    cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml"))
    cfg.DATASETS.TEST = ("val_dataset",)
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4  # Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª
    cfg.MODEL.WEIGHTS = MODEL_WEIGHTS
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5

    # âœ… ØªØ³Ø¬ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
    DatasetCatalog.register("val_dataset", lambda: get_dicts(VAL_JSON))
    MetadataCatalog.get("val_dataset").set(thing_classes=["person", "man", "woman", "child"])

    # ğŸ”¹ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    predictor = DefaultPredictor(cfg)

    # âœ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‚ÙŠÙ‘Ù… COCO
    evaluator = COCOEvaluator("val_dataset", cfg, False, output_dir=MODEL_DIR)
    val_loader = build_detection_test_loader(cfg, "val_dataset")
    results = inference_on_dataset(predictor.model, val_loader, evaluator)

    # ğŸ“Š Ø·Ø¨Ø§Ø¹Ø© Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
    print("\nğŸ“Š **Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Classification Ø¨Ø¯ÙˆÙ† Masking:**")
    print(results)
